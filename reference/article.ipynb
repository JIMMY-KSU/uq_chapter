{
 "metadata": {
  "name": "",
  "signature": "sha256:003120653e39dd63c23b5b06ad9c98ea4d767fe87a5c68c0bfb7c058c075cd33"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Probabilistic Programming in Python using PyMC\n",
      "\n",
      "## Abstract\n",
      "Probabilistic Programming (PP) allows flexible specification of statistical Bayesian models in code. PyMC3 is a new, open-source PP framework that features next generation Markov chain Monte Carlo (MCMC) sampling algorithms such as Hamiltonian Monte Carlo (HMC). In contrast to most other PP frameworks, PyMC3 allows model specification in Python using intuitive syntax. The software itself is written in pure Python which makes it very extensible. The model specification is transparently transcoded via Theano to C and compiled to machine code for maximum speed. Theano also natively supports automatic differentation for computing the gradient required for HMC. In addition, PyMC3 supports parallel sampling natively and allows saving traces to various backends including sqlite. Special syntax for describing general linear models allow for specification of hierarchical multifactor models into oneliners."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1. Getting started\n",
      "\n",
      "## Installation\n",
      "\n",
      "As PyMC3 is written in pure Python, installation is thus greatly simplified over PyMC2 which required compilation of Fortran code. PyMC3 has the following dependencies: `Theano`, `NumPy`, `SciPy`, and `Matplotlib`; as well as the following optional dependencies: `Pandas`, `Patsy`, `Statsmodels`.\n",
      "\n",
      "The code is hosted on GitHub at https://github.com/pymc-devs/pymc and is distributed under the liberal [Apache License 2.0](https://github.com/pymc-devs/pymc/blob/master/LICENSE) and contributions are encouraged.\n",
      "\n",
      "A complete Python installation can most easily be obtained by installing the free [`Anaconda Python Distribution`](https://store.continuum.io/cshop/anaconda/) by ContinuumIO. After successfull installation, `PyMC3` can be installed using `pip`:\n",
      "```\n",
      "pip install git+https://github.com/pymc-devs/pymc\n",
      "```\n",
      "\n",
      "## Model specification\n",
      "Consider the following linear Bayesian model:\n",
      "$$ \\alpha \\sim \\mathcal{N}(0, 1) $$\n",
      "$$ \\beta \\sim \\mathcal{N}(0, 1) $$\n",
      "$$ \\epsilon \\sim \\mathcal{U}(0, 1) $$\n",
      "$$ Y  \\sim \\mathcal{N}(\\alpha + X \\beta, \\epsilon) $$\n",
      "\n",
      "where $X$ is a vector of predictors, and $Y$ is a vector outcome variable; $\\alpha$ the intercept, and $\\beta$ the slope regression coefficients, and $\\epsilon$ the error term.\n",
      "\n",
      "The data might look as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_public(module):\n",
      "    import pprint\n",
      "    pprint.pprint([name for name in dir(module) if not name.startswith('_')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "size = 100\n",
      "X = np.linspace(0, 1, size)\n",
      "alpha = 1\n",
      "beta = 1\n",
      "Y = alpha + X*beta + np.random.randn(size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "plt.scatter(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7f15449c6350>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndACIxP8Dr3OqBlgD2B4AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f1545608f50>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymc as pm\n",
      "\n",
      "with pm.Model() as model:\n",
      "    alpha = pm.Normal('alpha', mu=0, sd=1)\n",
      "    beta = pm.Normal('beta', mu=0, sd=1)\n",
      "    eps = pm.Uniform('eps', lower=0, upper=1)\n",
      "    Y_obs = pm.Normal('Y_obs', mu=alpha + beta * X, sd=eps, observed=Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, with a few minor modifications, specification of this model in Python code using `PyMC3` closely follows the statistical model printed above. `PyMC3` comes with most commonly used discrete and continuous probability distributions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_public(pm.distributions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Bernoulli',\n",
        " 'Beta',\n",
        " 'BetaBin',\n",
        " 'Binomial',\n",
        " 'Bound',\n",
        " 'Categorical',\n",
        " 'Cauchy',\n",
        " 'ChiSquared',\n",
        " 'ConstantDist',\n",
        " 'Continuous',\n",
        " 'DensityDist',\n",
        " 'Dirichlet',\n",
        " 'Discrete',\n",
        " 'DiscreteUniform',\n",
        " 'Distribution',\n",
        " 'Exponential',\n",
        " 'Flat',\n",
        " 'Gamma',\n",
        " 'Geometric',\n",
        " 'HalfCauchy',\n",
        " 'HalfNormal',\n",
        " 'InverseGamma',\n",
        " 'Laplace',\n",
        " 'Lognormal',\n",
        " 'Multinomial',\n",
        " 'MvNormal',\n",
        " 'NegativeBinomial',\n",
        " 'Normal',\n",
        " 'Pareto',\n",
        " 'Poisson',\n",
        " 'T',\n",
        " 'Tpos',\n",
        " 'Uniform',\n",
        " 'Wald',\n",
        " 'Weibull',\n",
        " 'Wishart',\n",
        " 'ZeroInflatedPoisson',\n",
        " 'continuous',\n",
        " 'discrete',\n",
        " 'dist_math',\n",
        " 'distribution',\n",
        " 'logtransform',\n",
        " 'meta',\n",
        " 'multivariate',\n",
        " 'simplextransform',\n",
        " 'special',\n",
        " 'timeseries',\n",
        " 'transform',\n",
        " 'transforms']\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first argument is the name of the random variable (RV). Following arguments specify the priors of the distribution which are described in the doc string:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(pm.Normal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class Normal in module pymc.distributions.continuous:\n",
        "\n",
        "class Normal(pymc.distributions.distribution.Continuous)\n",
        " |  Normal log-likelihood.\n",
        " |  \n",
        " |  .. math::\n",
        " |      f(x \\mid \\mu,   au) = \\sqrt{\f",
        "rac{       au}{2\\pi}} \\exp\\left\\{ -\f",
        "rac{   au}{2} (x-\\mu)^2 \r",
        "ight\\}\n",
        " |  \n",
        " |  Parameters\n",
        " |  ----------\n",
        " |  mu : float\n",
        " |      Mean of the distribution.\n",
        " |  tau : float\n",
        " |      Precision of the distribution, which corresponds to\n",
        " |      :math:`1/\\sigma^2` (tau > 0).\n",
        " |  sd : float\n",
        " |      Standard deviation of the distribution. Alternative parameterization.\n",
        " |  \n",
        " |  .. note::\n",
        " |  - :math:`E(X) = \\mu`\n",
        " |  - :math:`Var(X) = 1/        au`\n",
        " |  \n",
        " |  Method resolution order:\n",
        " |      Normal\n",
        " |      pymc.distributions.distribution.Continuous\n",
        " |      pymc.distributions.distribution.Distribution\n",
        " |      __builtin__.object\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __init__(self, mu=0.0, tau=None, sd=None, *args, **kwargs)\n",
        " |  \n",
        " |  logp(self, value)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from pymc.distributions.distribution.Distribution:\n",
        " |  \n",
        " |  __getnewargs__(self)\n",
        " |  \n",
        " |  default(self)\n",
        " |  \n",
        " |  get_test_val(self, val, defaults)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Class methods inherited from pymc.distributions.distribution.Distribution:\n",
        " |  \n",
        " |  dist(cls, *args, **kwargs) from __builtin__.type\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Static methods inherited from pymc.distributions.distribution.Distribution:\n",
        " |  \n",
        " |  __new__(cls, name, *args, **kwargs)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from pymc.distributions.distribution.Distribution:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make special note of the `observed` keyword argument supplied here:\n",
      "```python\n",
      "    Y_obs = pm.Normal('Y_obs', mu=alpha + beta * X, sd=eps, observed=Y)\n",
      "```\n",
      "\n",
      "This argument expects a `numpy.ndarray` object or a `pandas.DataFrame` and turns Y_obs into a likelihood function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also note that this command executes very fast. That's because no computation has taken place yet (more on this below).\n",
      "\n",
      "Finally, let's take a look at this line:\n",
      "```python\n",
      "with pm.Model() as model:\n",
      "```\n",
      "\n",
      "First, the `with` statement instantiates a new `pm.Model()` object and binds it to `model`. Moreover, the `with` statement modifies how each indentend function below it (i.e. same context) gets called. Specifically, each function in the context gets passed in the `model` object. The code above would thus be equivalent to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_wo_context = pm.Model()\n",
      "alpha = pm.Normal('alpha', 0, 1, model=model_wo_context)\n",
      "beta = pm.Normal('beta', 0, 1, model=model_wo_context)\n",
      "eps = pm.Uniform('eps', 0, 1, model=model_wo_context)\n",
      "Y_obs = pm.Normal('Y_obs', alpha + beta * X, observed=Y, model=model_wo_context)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the `with` statement provides syntactic sugar and binds all RVs to a common container. `PyMC2` required all RVs to be passed as a `list` to a new `Model` object."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Theano` has advanced matrix notation capabilities that enable `PyMC3` to handle multivariate statistics, including advanced indexing and slicing. Using matrix algebra, the above model can succinctly be rewritten as:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano.tensor as T\n",
      "\n",
      "# Turn X into a 2-D array with a column of 1s for the intercept\n",
      "X_1 = np.vstack([np.ones_like(X), X])\n",
      "\n",
      "with pm.Model() as model_matrix:\n",
      "    theta = pm.Normal('theta', 0, 1, shape=(2, 1))\n",
      "    eps = pm.Uniform('eps', 0, 1)\n",
      "    Y_obs = pm.Normal('Y_obs', T.dot(theta.T, X_1), observed=Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `shape` kwarg turns theta into random vector with 2 elements, both of which are distributed according to the standard normal distribution.\n",
      "\n",
      "To perform the reduction in the `Y_obs` instantiaion we use the `theano` `dot()` function to compute the dot product. At this point it is worth noting that RVs in `PyMC3` behave like `theano` expressions which makes them very versatile. For example, using `theano`'s sigmoid function from the neural net (`nnet`) submodule we can easily turn this linear regression into a logistic regression:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Turn X into a 2-D array with a column of 1s for the intercept\n",
      "Y_logistic = Y > np.median(Y) # Binarize Y by splitting at the 50% percentile\n",
      "\n",
      "with pm.Model() as model_logistic:\n",
      "    theta = pm.Normal('theta', 0, 1, shape=(2, 1))\n",
      "    eps = pm.Uniform('eps', 0, 1)\n",
      "    Y_obs = pm.Bernoulli('Y_obs', p=T.nnet.sigmoid(T.dot(theta.T, X_1)), \n",
      "                         observed=Y_logistic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further below we describe how more complex GLMs can easily be created in one line using the `glm` submodule of `PyMC3` but let us first turn our attention to inference."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Inference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As mentioned above, the code examples above have not actually performed any computation. All what was done was to compute -- behind the scenes -- a `theano` expression graph that allows computation of the summed log probability of the model. On demand, we can ask `theano` to perform algebraic simplifications and compile the symbolic computation graph to C-code and then natively using the system's `gcc` compiler. All of this functionality happens transparently and does not burden the `PyMC3` code base. \n",
      "\n",
      "To actually run MCMC sampling to generate posterior samples we have instantiate a step object that corresponds to a certain kind of MCMC. The `pymc.step_methods` submodule contains the following samplers, as well as proposal distributions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_public(pm.step_methods)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['BinaryMetropolis',\n",
        " 'CauchyProposal',\n",
        " 'CompoundStep',\n",
        " 'ElemwiseCategoricalStep',\n",
        " 'HamiltonianMC',\n",
        " 'LaplaceProposal',\n",
        " 'Metropolis',\n",
        " 'MultivariateNormalProposal',\n",
        " 'NUTS',\n",
        " 'NormalProposal',\n",
        " 'PoissonProposal',\n",
        " 'Slice',\n",
        " 'arraystep',\n",
        " 'compound',\n",
        " 'gibbs',\n",
        " 'hmc',\n",
        " 'metropolis',\n",
        " 'nuts',\n",
        " 'quadpotential',\n",
        " 'slicer']\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, `PyMC3` supports all samplers that are commonly included in other propalistic programming frameworks like `BUGS` or `JAGS`, including Metropolis Hastings with various proposal distributions and Slice sampling. Of special note are the new class of Hamiltonian Monte Carlo samplers like `HamiltonianMC` as well as the auto-tuned version of it -- the No-U-Turn Sampler (`NUTS`). This last sampling algorithm is one of the main selling points of the new `stan` MCMC package (CITE)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}